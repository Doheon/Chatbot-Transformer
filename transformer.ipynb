{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import sentencepiece as spm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "with open('all.txt', 'w', encoding='utf8') as f:\n",
    "    f.write('\\n'.join(questions))\n",
    "    f.write('\\n'.join(answers))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "corpus = \"all.txt\"\n",
    "prefix = \"chatbot\"\n",
    "vocab_size = 16000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "vocab_file = \"chatbot.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "line = \"안녕하세요 만나서 반갑습니다\"\n",
    "pieces = vocab.encode_as_pieces(line)\n",
    "ids = vocab.encode_as_ids(line)\n",
    "\n",
    "\n",
    "print(line)\n",
    "print(pieces)\n",
    "print(ids)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "안녕하세요 만나서 반갑습니다\n",
      "['▁안녕하세요', '▁만나서', '▁반갑습니다']\n",
      "[4626, 1930, 8499]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "START_TOKEN = [2]\n",
    "END_TOKEN = [3]\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "    zeros1 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "    zeros2 = np.zeros(MAX_LENGTH, dtype=int)\n",
    "    sentence1 = START_TOKEN + vocab.encode_as_ids(sentence1) + END_TOKEN\n",
    "    zeros1[:len(sentence1)] = sentence1[:MAX_LENGTH]\n",
    "\n",
    "    sentence2 = START_TOKEN + vocab.encode_as_ids(sentence2) + END_TOKEN\n",
    "    zeros2[:len(sentence2)] = sentence2[:MAX_LENGTH]\n",
    "\n",
    "    tokenized_inputs.append(zeros1)\n",
    "    tokenized_outputs.append(zeros2)\n",
    "  return tokenized_inputs, tokenized_outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "questions_encode, answers_encode = tokenize_and_filter(questions, answers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(questions_encode[0])\n",
    "print(answers_encode[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[    2  5566 14968  3210   111     3     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "[   2 5192  217 5936    7    3    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, questions, answers):\n",
    "        questions = np.array(questions)\n",
    "        answers = np.array(answers)\n",
    "        self.inputs = questions\n",
    "        self.dec_inputs = answers[:,:-1]\n",
    "        self.outputs = answers[:,1:]\n",
    "        self.length = len(questions)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return (self.inputs[idx], self.dec_inputs[idx], self.outputs[idx])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "dataset = SequenceDataset(questions_encode, answers_encode)\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from torch.nn import Transformer\n",
    "from torch import nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class TFModel(nn.Module):\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TFModel, self).__init__()\n",
    "        self.transformer = Transformer(ninp, nhead, dim_feedforward=nhid, num_encoder_layers=nlayers, num_decoder_layers=nlayers,dropout=dropout)\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.pos_encoder_d = PositionalEncoding(ninp, dropout)\n",
    "        self.encoder_d = nn.Embedding(ntoken, ninp)\n",
    "\n",
    "        self.ninp = ninp\n",
    "        self.ntoken = ntoken\n",
    "\n",
    "        self.linear = nn.Linear(ninp, ntoken)\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, tgt, srcmask, tgtmask, srcpadmask, tgtpadmask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "\n",
    "        tgt = self.encoder_d(tgt) * math.sqrt(self.ninp)\n",
    "        tgt = self.pos_encoder_d(tgt)\n",
    "\n",
    "\n",
    "        output = self.transformer(src.transpose(0,1), tgt.transpose(0,1), srcmask, tgtmask, src_key_padding_mask=srcpadmask, tgt_key_padding_mask=tgtpadmask)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "def gen_attention_mask(x):\n",
    "    mask = torch.eq(x, 0)\n",
    "    return mask"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "source": [
    "device = torch.device(\"cuda\", index=1)\n",
    "\n",
    "lr = 1e-4\n",
    "model = TFModel(vocab_size+7, 256, 8, 512, 2, 0.1).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "source": [
    "epoch = 30\n",
    "from tqdm import tqdm\n",
    "\n",
    "model.train()\n",
    "for i in range(epoch):\n",
    "    batchloss = 0.0\n",
    "    progress = tqdm(dataloader)\n",
    "    for (inputs, dec_inputs, outputs) in progress:\n",
    "        optimizer.zero_grad()\n",
    "        src_mask = model.generate_square_subsequent_mask(MAX_LENGTH).to(device)\n",
    "        src_padding_mask = gen_attention_mask(inputs).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(MAX_LENGTH-1).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(dec_inputs).to(device)\n",
    "\n",
    "        result = model(inputs.to(device), dec_inputs.to(device), src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
    "        loss = criterion(result.permute(1,2,0), outputs.to(device).long())\n",
    "        progress.set_description(\"{:0.3f}\".format(loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batchloss += loss\n",
    "    print(\"epoch:\",i+1,\"|\",\"loss:\",batchloss.cpu().item() / len(dataloader))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.959: 100%|██████████| 185/185 [00:09<00:00, 20.16it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 1 | loss: 1.8828087059227196\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.942: 100%|██████████| 185/185 [00:08<00:00, 20.82it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 2 | loss: 0.9739796406513935\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.923: 100%|██████████| 185/185 [00:08<00:00, 22.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 3 | loss: 0.9115835653769003\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.912: 100%|██████████| 185/185 [00:08<00:00, 21.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 4 | loss: 0.8829720986855997\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.959: 100%|██████████| 185/185 [00:08<00:00, 21.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 5 | loss: 0.861990686365076\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.868: 100%|██████████| 185/185 [00:08<00:00, 20.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 6 | loss: 0.8425723514041386\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.904: 100%|██████████| 185/185 [00:08<00:00, 22.06it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 7 | loss: 0.8240846376161317\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.839: 100%|██████████| 185/185 [00:08<00:00, 21.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 8 | loss: 0.8053272144214527\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.861: 100%|██████████| 185/185 [00:08<00:00, 21.16it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 9 | loss: 0.7861398232949747\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.793: 100%|██████████| 185/185 [00:08<00:00, 21.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 10 | loss: 0.7659728179106842\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.676: 100%|██████████| 185/185 [00:08<00:00, 21.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 11 | loss: 0.7451116613439611\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.636: 100%|██████████| 185/185 [00:08<00:00, 21.84it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 12 | loss: 0.7248309986011402\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.743: 100%|██████████| 185/185 [00:09<00:00, 19.96it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 13 | loss: 0.7038217080605996\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.596: 100%|██████████| 185/185 [00:08<00:00, 20.68it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 14 | loss: 0.6829455813846073\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.667: 100%|██████████| 185/185 [00:08<00:00, 21.80it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 15 | loss: 0.6613200007258235\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.633: 100%|██████████| 185/185 [00:08<00:00, 21.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 16 | loss: 0.6399022695180532\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.615: 100%|██████████| 185/185 [00:08<00:00, 21.90it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 17 | loss: 0.6175418750659839\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.601: 100%|██████████| 185/185 [00:08<00:00, 22.43it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 18 | loss: 0.5956226245777027\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.630: 100%|██████████| 185/185 [00:09<00:00, 19.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 19 | loss: 0.5732904382654138\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.496: 100%|██████████| 185/185 [00:08<00:00, 21.69it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 20 | loss: 0.5513939110008446\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.507: 100%|██████████| 185/185 [00:08<00:00, 21.30it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 21 | loss: 0.5286682541305955\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.480: 100%|██████████| 185/185 [00:08<00:00, 21.46it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 22 | loss: 0.5066682970201647\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.460: 100%|██████████| 185/185 [00:08<00:00, 21.40it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 23 | loss: 0.48444976806640627\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.428: 100%|██████████| 185/185 [00:08<00:00, 22.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 24 | loss: 0.4617009755727407\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.467: 100%|██████████| 185/185 [00:08<00:00, 22.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 25 | loss: 0.43948953989389783\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.500: 100%|██████████| 185/185 [00:08<00:00, 21.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 26 | loss: 0.4179861945074958\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.331: 100%|██████████| 185/185 [00:08<00:00, 22.72it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 27 | loss: 0.39681738776129644\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.342: 100%|██████████| 185/185 [00:08<00:00, 20.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 28 | loss: 0.37577456912478885\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.333: 100%|██████████| 185/185 [00:08<00:00, 21.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 29 | loss: 0.35584098197318415\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0.345: 100%|██████████| 185/185 [00:08<00:00, 21.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 30 | loss: 0.33466512319203967\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "source": [
    "torch.save(model.state_dict(), \"chatbot.pth\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input = torch.tensor([START_TOKEN + vocab.encode_as_ids(sentence) + END_TOKEN]).to(device)\n",
    "    output = torch.tensor([START_TOKEN]).to(device)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    model.eval()\n",
    "    for i in range(MAX_LENGTH):\n",
    "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n",
    "        tgt_mask = model.generate_square_subsequent_mask(output.shape[1]).to(device)\n",
    "\n",
    "        src_padding_mask = gen_attention_mask(input).to(device)\n",
    "        tgt_padding_mask = gen_attention_mask(output).to(device)\n",
    "\n",
    "        predictions = model(input, output, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask).transpose(0,1)\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = torch.LongTensor(torch.argmax(predictions.cpu(), axis=-1))\n",
    "\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if torch.equal(predicted_id[0][0], torch.tensor(END_TOKEN[0])):\n",
    "            break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = torch.cat([output, predicted_id.to(device)], axis=1)\n",
    "\n",
    "    return torch.squeeze(output, axis=0).cpu().numpy()\n",
    "\n",
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    predicted_sentence = vocab.Decode(list(map(int,[i for i in prediction if i < vocab_size+7])))\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "source": [
    "model.load_state_dict(torch.load(\"chatbot.pth\"))\n",
    "result = predict(\"난 뭘 해야 할까?\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Input: 난 뭘 해야 할까?\n",
      "Output: 가장 중요한 것 같아요 .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('doheon': conda)"
  },
  "interpreter": {
   "hash": "849767edceeeddf53965c2c22dc0d6f4cc62af5f2af22e684245cca2d0b8102d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}